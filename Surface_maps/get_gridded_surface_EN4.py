### work in progress ###
### replication of  EN4_processing/GEN_MOD_Dave_example_profile_validation.py
### purpose > make gridded version of en4 data?

from config import config
import sys

cfg = config() # initialise variables in python

from NEMO_validation._utils import landmask
import coast
import xarray as xr
import numpy as np
import pandas as pd
import os
from coast import crps_util as cu
import numpy as np

import time

class gridded_en4(object):

    def __init__(self):
        # Name of the run -- used mainly for naming output files
        self.run_name='%d%02d'%(startyear,month)
        
        # File paths (All)
        self.fn_dom = cfg.dn_dom + cfg.grid_nc
        self.fn_dat = "%s%s%02d*T.nc"%(cfg.dn_dat, startyear, month) 
        
        # Make out directory
        print(os.popen(f"mkdir -p {cfg.dn_out}").read())
        
        # Generated by pre_process_en4_monthly.py
        self.fn_append = "_processed_%d%02d.nc"%(startyear,month)
        self.fn_prof = cfg.dout_en4 + cfg.region + fn_append

        # user inputs
        args = sys.argv
        
        self.exper = args[1]
        self.startyear=int(args[2])
        self.month=int(args[3])
        self.endyear=int(args[4])
        self.grid=args[5]

        self.start_date = np.datetime64(str(self.startyear)+"-01-01")
        self.end_date = np.datetime64(str(self.endyear)+"-01-01")
        
    def nemo(self):
        # CREATE NEMO OBJECT and read in NEMO data.
        nemo = coast.Gridded(fn_dat, fn_dom, multiple=True, 
                             config=cfg.fn_cfg_nemo)
        
        # Extract latitude and longitude array
        lon = nemo.dataset.longitude.values.squeeze()
        lat = nemo.dataset.latitude.values.squeeze()
        
        # Extract time indices between start and end dates
        t_ind = nemo.dataset.time.values>=start_date
        nemo.dataset = nemo.dataset.isel(t_dim=t_ind)
        t_ind = nemo.dataset.time.values<end_date
        nemo.dataset = nemo.dataset.isel(t_dim=t_ind)
        
        nemo.dataset = landmask.add_landmask(nemo.dataset)
        nemo.dataset.rename({"depth_0": "depth"})
        
        # Extract model variables.
        nemo.dataset = nemo.dataset[["temperature",
                                          "salinity",
                                          "bathymetry",
                                          "bottom_level",
                                          "landmask"]]
        return nemo.dataset

    def en4_profiles(self):
    
        # CREATE EN4 PROFILE OBJECT 
        prof = coast.Profile(config=cfg.fn_cfg_prof)
        prof.dataset = xr.open_dataset(self.fn_prof, chunks={'id_dim':10000})
        
        # Extract EN4 variables.
        prof.dataset = prof.dataset[["potential_temperature",
                                     "practical_salinity",
                                      "depth"]]
        
        prof.dataset = prof.dataset.rename({
                                          "potential_temperature":"temperature",
                                          "practical_salinity":"salinity"})
        
        # Cut out a time window
        prof = prof.time_slice(date0=start_date, date1=end_date)
        return prof
    
    def interp_model_to_obs_profiles(self):

        # Interpolate model to obs using obs_operator(). This is slow.
        print("Extracting profiles from model - is slow ")
        model_profiles = profile.obs_operator(nemo)
        
        # Discard profiles where the interpolation distance is larger than 5km.
        keep_indices = model_profiles.dataset.interp_dist <= 5 
        model_profiles = model_profiles.isel(id_dim=keep_indices)
        profile = profile.isel(id_dim=keep_indices)
        if np.sum(~keep_indices.values)>0:
        	print(f"""Dropped {np.sum(~keep_indices.values)}
                          profiles: too far in space""")
        
        # Throw away profile where the interpolation time is larger than 12h
        keep_indices = np.abs(model_profiles.dataset.interp_lag)\
                             <= np.timedelta64(12, 'h') 
        model_profiles = model_profiles.isel(id_dim=keep_indices)
        profile = profile.isel(id_dim=keep_indices)
        if np.sum(~keep_indices.values)>0:
        	print(f"""Dropped {np.sum(~keep_indices.values)} profiles:  
                        too far in time""")
        
    def analysis(self):
        analysis = coast.ProfileAnalysis()
        
        # Interpolate model profiles onto observation depths
        model_profiles_interp = analysis.interpolate_vertical(model_profiles, 
                                          profile, interp_method="linear")
        print('Model interpolated to obs depths')
        
        # Reference depths (in metres)
        ref_depth = np.concatenate((np.arange(1,100,2),
                                    np.arange(100,300,5), 
                                    np.arange(300, 1000, 50), 
                                    np.arange(1000,4000,100)))
        
        # Vertical interpolation of model profiles to reference depths
        model_profiles_interp_ref_full = analysis.interpolate_vertical(
                                       model_profiles_interp, ref_depth)
        print('Model interpolated to ref depths')
        
        # Interpolation of obs profiles to reference depths
        profile_interp_ref_full = analysis.interpolate_vertical(
                                                             profile, ref_depth)
        print('Obs interpolated to reference depths')
        
        # Average depth-interpolated obs profiles onto 
        #horizontal-space/time model grid
        model_profiles_interp_ref, profile_interp_ref = self.reduce_resolution(
                   model_profiles_interp_ref_full, profile_interp_ref_full)
        
        # Surface & Bottom averaging
        surface_def = 5
        model_profiles_surface = analysis.depth_means(model_profiles_interp_ref, 
                                                      [0, surface_def])
         m_prof_surf.dataset = m_prof_surf.dataset.rename(
                                            {'temperature':'temperature_model',
                                             'salinity':'salinity_model'})
        
        obs_profiles_surface = analysis.depth_means(profile_interp_ref, 
                                                    [0, surface_def])
        
        surface_data = xr.merge((m_prof_surf.dataset
                                 obs_profiles_surface.dataset),
        			   compat='override')
        
        surface_data.to_netcdf(dn_out+"surface_data_{0}.nc".format(run_name))

