### work in progress ###
### replication of  EN4_processing/GEN_MOD_Dave_example_profile_validation.py
### purpose > make gridded version of en4 data?

from PythonEnvCfg.config import config, bounds

cfg = config() # initialise variables in python
bdy = bounds("AMM15")

from NEMO_validation._utils import landmask
from dask.diagnostics import ProgressBar
import coast
import xarray as xr
import numpy as np
import pandas as pd
import os
from coast import crps_util as cu
import numpy as np
import sys

import time

class gridded_en4(object):

    def __init__(self):

        # user inputs
        args = sys.argv
        startyear=int(args[1])
        month=int(args[2])
        endyear=int(args[3])

        # File paths 
        self.fn_dom = cfg.dn_dom + cfg.grid_nc
        self.fn_dat = cfg.dn_dat + "*T.nc"
        self.fn_out = cfg.dn_out + 'surface_maps/'
        
        # Make out directory
        print(os.popen(f"mkdir -p {cfg.dn_out}").read())
        
        # Generated by pre_process_en4_monthly.py
        #fn_append = "_processed_%d%02d.nc"%(startyear,month)
        fn_append = "_processed_*.nc"
        self.fn_prof = cfg.dout_en4 + cfg.region + fn_append
        self.en4_path = cfg.dout_en4 + cfg.region 
        
        self.start_date = np.datetime64(str(startyear)+"-01-01")
        self.end_date = np.datetime64(str(endyear)+"-01-01")

        self.month_list = np.arange(self.start_date, self.end_date, 
                                    dtype="datetime64[M]")
        
    def model_data(self):
        """ 
        Bin model data to common grid.
        """

        model_monthly = []
        for date in self.month_list:
            print (date)
            # get model data under alias ds
            date_str = date.astype("str").replace("-","")

            fn_surf = "profiles/gridded_model_surface_data_" + date_str + ".nc"
            ds = xr.load_dataset(cfg.dn_out + fn_surf)

            # Extract model variables.
            ds = ds[["temperature", "salinity"]]

            # average over month
            ds = ds.mean("t_dim")

            # get bin mean
            ds = self.bin_data(ds, lon_coord="longitude", 
                                   lat_coord="latitude")


            # assign month coordinate
            ds = ds.expand_dims("t_dim")
            time_arr = xr.DataArray([date], dims="t_dim")
            ds = ds.assign_coords({"time":time_arr})

            model_monthly.append(ds)
            #fout_append = "binned_model_monthly_mean_model_data_" + date_str \
            #             + ".nc"
            #with ProgressBar():
            #    ds.to_netcdf(cfg.dn_dat + fout_append)
        # join months and save
        ds_all = xr.concat(model_monthly, dim="t_dim")
        fout_append = "surface_maps/binned_model_monthly_mean_%s_%s.nc"%(
                      self.month_list[0], self.month_list[-1])
        ds_all.to_netcdf(cfg.dn_out + fout_append)

    def merge_model_months(self):
        """ merge model data into one file following binning opperation. """

        def proc(ds):
            print (ds)
            return ds
        fout_append = "binned_model_monthly_mean_model_data_*.nc"
        ds = xr.open_mfdataset(cfg.dn_dat + fout_append, combine="nested", 
                               concat_dim="t_dim", parallel=True, preprocess=proc)
    def bin_data(self, ds, lon_coord="longitude", lat_coord="latitude", cell_num=20, coord_dims=False):
        """ Bin lat/lons into regular grid """

        lons = np.linspace(bdy.lonbounds[0], bdy.lonbounds[1], cell_num + 1)
        lats = np.linspace(bdy.latbounds[0], bdy.latbounds[1], cell_num + 1)
        lon_labs = (lons[1:] + lons[:-1]) / 2
        lat_labs = (lats[1:] + lats[:-1]) / 2
        #ds_binned = xhist.histogram(ds.temperature, bins=[lons])
        #print (ds_binned)
        #print (dskl)
        #ds = ds.chunk({"x_dim":10, "y_dim":10})
        #ds = ds.stack(h=["latitude","longitude"])
        #ds = ds.set_index(h=["latitude"])
        #ds = ds.unstack("h")
        #print (ds)
        #ds = ds.groupby_bins("x_dim", lons, labels=lon_labs)
        #ds = ds.groupby_bins(lat_coord, lats, labels=lat_labs)
        bins = []
        for (lon, xg) in ds.groupby_bins(lon_coord, lons, labels=lon_labs):
            lat_bins = []
            for (lat, yg) in xg.groupby_bins(lat_coord, lats, labels=lat_labs):
                yg = yg.mean("stacked_y_dim_x_dim")
                yg = yg.assign_coords(longitude=("x_dim",[lon]),
                                      latitude=("y_dim",[lat]))
                yg = yg.swap_dims(x_dim="longitude",y_dim="latitude")
                lat_bins.append(yg)
            lat_bins = xr.concat(lat_bins, dim="latitude")
            bins.append(lat_bins)
        ds = xr.concat(bins, dim="longitude")
        ds = ds.sortby("latitude")
        ds = ds.sortby("longitude")
        #ds = ds.chunk({"x_dim_bins":-1,"y_dim_bins":-1})
        return ds

    def grid_en4_profiles(self):
        """
        Create gridded surface en4 data.

        Load en4 data. Expand dimentions to time, lat and lon. Then bin
        over coarse lat/lon intervals.
        """
    
        # create en4 profile object 
        prof = coast.Profile(config=cfg.fn_cfg_prof)
        
        en4_monthly = []
        for date in self.month_list:
            # load en4
            date_str = date.astype("str").replace("-","")
            print (date_str)
            fn_append = "_processed_" + date_str + ".nc"
            en4 = xr.load_dataset(self.en4_path + fn_append)

            # select variables
            en4 = en4[["potential_temperature", "practical_salinity",
                       "depth"]]

            en4 = en4.set_coords("depth")
            en4 = en4.where(en4.depth < 5, drop=True).mean("z_dim")
            en4 = en4.dropna(dim="id_dim", how="all")

            # expand to 3D 
            en4 = en4.set_index(id_dim=["time","longitude","latitude"])
            en4 = en4.unstack("id_dim")

            # bin over lat/lons
            en4 = self.bin_data(en4)

            print (sdjklaf)
            # time average for each lat/lon bin
            en4 = en4.mean("time").expand_dims("t_dim")

            # assign month coordinate
            time_arr = xr.DataArray([date], dims="t_dim")
            en4 = en4.assign_coords({"time":time_arr})
            en4_monthly.append(en4)

        # join months and save
        en4_all = xr.concat(en4_monthly, dim="t_dim")
        fout_append = "gridded_en4_monthly_mean_%s_%s.nc"%(
                      self.month_list[0], self.month_list[-1])
        en4_all.to_netcdf(cfg.dout_en4 + fout_append)
            
    def get_gridded_en4_climatology(self):
        """ Get seasonal climatololy from gridded en4 data """

        # read gridded surface en4
        fout_append = "gridded_en4_monthly_mean_%s_%s.nc"%(
                      self.month_list[0], self.month_list[-1])
        en4 = xr.open_dataset(cfg.dout_en4 + fout_append)
        
        # calculate climatology
        clim = coast.Climatology()
        clim_mean = clim.make_climatology(en4, "season", 
                    fn_out=self.fn_out + "en4_gridded_surface_climatology.nc")

    def get_binned_model_climatology(self):
        """ Get seasonal climatololy from binned data """

        # read gridded surface en4
        fout_append = "surface_maps/binned_model_monthly_mean_%s_%s.nc"%(
                      self.month_list[0], self.month_list[-1])
        ds = xr.open_dataset(cfg.dn_out + fout_append)
        
        # calculate climatology
        clim = coast.Climatology()
        clim_mean = clim.make_climatology(ds, "season", 
                   fn_out=self.fn_out + "binned_model_surface_climatology.nc")
            
gr = gridded_en4()
#gr.model_data()
#gr.grid_en4_profiles()
#gr.get_gridded_en4_climatology()
#gr.merge_model_months()
gr.get_binned_model_climatology()
